{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "volmeta = pd.read_csv('updatedvolumemetadata.tsv', sep = '\\t')\n",
    "#seperate metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>author</th>\n",
       "      <th>authordate</th>\n",
       "      <th>title</th>\n",
       "      <th>latestcomp</th>\n",
       "      <th>hathidate</th>\n",
       "      <th>imprint</th>\n",
       "      <th>gutenstring</th>\n",
       "      <th>enumcron</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>...</th>\n",
       "      <th>contents</th>\n",
       "      <th>instances</th>\n",
       "      <th>genre</th>\n",
       "      <th>audience</th>\n",
       "      <th>authgender</th>\n",
       "      <th>multiplehtids</th>\n",
       "      <th>comments</th>\n",
       "      <th>coder</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Trimmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loc.ark+=13960=t5p851b8s</td>\n",
       "      <td>Reid, Stuart J.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lord John Russell</td>\n",
       "      <td>1895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York;Harper &amp; brothers;1</td>\n",
       "      <td>Reid, Stuart J. | Lord John Russell</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>27553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hvd.32044070870779</td>\n",
       "      <td>Smiles, Samuel,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lives of the engineers</td>\n",
       "      <td>1879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;J. Murray;1874-1877.</td>\n",
       "      <td>Smiles, Samuel | Lives of the Engineers</td>\n",
       "      <td>v. 5</td>\n",
       "      <td>27710</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio | short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 people, mixed together (not one per chapter)</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdp.39015005892362</td>\n",
       "      <td>Cruttwell, Maud.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luca Signorelli</td>\n",
       "      <td>1899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;G. Bell &amp; sons;1899.</td>\n",
       "      <td>Cruttwell, Maud | Luca Signorelli</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>27759</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdp.39015051108531</td>\n",
       "      <td>Bettany, George Thomas,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Life of Charles Darwin</td>\n",
       "      <td>1887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;W. Scott;1887.</td>\n",
       "      <td>Bettany, George Thomas | Life of Charles Darwin</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>28380</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loc.ark+=13960=t6b27z54n</td>\n",
       "      <td>Gay, Sydney Howard,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James Madison</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston;New York;Houghton, Mi</td>\n",
       "      <td>Gay, Sydney Howard | James Madison</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>28992</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid                   author authordate  \\\n",
       "0  loc.ark+=13960=t5p851b8s          Reid, Stuart J.        NaN   \n",
       "1        hvd.32044070870779          Smiles, Samuel,        NaN   \n",
       "2        mdp.39015005892362         Cruttwell, Maud.        NaN   \n",
       "3        mdp.39015051108531  Bettany, George Thomas,        NaN   \n",
       "4  loc.ark+=13960=t6b27z54n      Gay, Sydney Howard,        NaN   \n",
       "\n",
       "                    title  latestcomp  hathidate  \\\n",
       "0       Lord John Russell        1895        NaN   \n",
       "1  Lives of the engineers        1879        NaN   \n",
       "2         Luca Signorelli        1899        NaN   \n",
       "3  Life of Charles Darwin        1887        NaN   \n",
       "4           James Madison        1889        NaN   \n",
       "\n",
       "                        imprint  \\\n",
       "0  New York;Harper & brothers;1   \n",
       "1   London;J. Murray;1874-1877.   \n",
       "2   London;G. Bell & sons;1899.   \n",
       "3         London;W. Scott;1887.   \n",
       "4  Boston;New York;Houghton, Mi   \n",
       "\n",
       "                                       gutenstring enumcron gbindex  ...  \\\n",
       "0              Reid, Stuart J. | Lord John Russell  <blank>   27553  ...   \n",
       "1          Smiles, Samuel | Lives of the Engineers     v. 5   27710  ...   \n",
       "2                Cruttwell, Maud | Luca Signorelli  <blank>   27759  ...   \n",
       "3  Bettany, George Thomas | Life of Charles Darwin  <blank>   28380  ...   \n",
       "4               Gay, Sydney Howard | James Madison  <blank>   28992  ...   \n",
       "\n",
       "   contents  instances        genre audience authgender  multiplehtids  \\\n",
       "0       NaN        NaN          bio      NaN          u            NaN   \n",
       "1       NaN        NaN  bio | short      NaN          m            NaN   \n",
       "2       NaN        NaN          bio      NaN          f            NaN   \n",
       "3       NaN        NaN          bio      NaN          m            NaN   \n",
       "4       NaN        NaN          bio      NaN          u            NaN   \n",
       "\n",
       "                                         comments   coder           Folder  \\\n",
       "0                                             NaN  morgan  gutenbiotrimmed   \n",
       "1  2 people, mixed together (not one per chapter)  morgan  gutenbiotrimmed   \n",
       "2                                             NaN  morgan  gutenbiotrimmed   \n",
       "3                                             NaN  morgan  gutenbiotrimmed   \n",
       "4                                             NaN  morgan  gutenbiotrimmed   \n",
       "\n",
       "   Trimmed  \n",
       "0  Trimmed  \n",
       "1  Trimmed  \n",
       "2  Trimmed  \n",
       "3  Trimmed  \n",
       "4  Trimmed  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volmeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly dutch\n"
     ]
    }
   ],
   "source": [
    "def simplify_genre(genrestring):\n",
    "    genres = [x.strip() for x in genrestring.split('|')]\n",
    "    if 'bio' in genres:\n",
    "        return 'bio'\n",
    "    elif 'fic' in genres:\n",
    "        return 'fic'\n",
    "    else:\n",
    "        print('anomaly', genrestring)\n",
    "        return float('nan')\n",
    "\n",
    "volmeta['simplegenre'] = volmeta['genre'].apply(simplify_genre)\n",
    "#function to simplify genre since we added more fine metadata like bio|short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>author</th>\n",
       "      <th>authordate</th>\n",
       "      <th>title</th>\n",
       "      <th>latestcomp</th>\n",
       "      <th>hathidate</th>\n",
       "      <th>imprint</th>\n",
       "      <th>gutenstring</th>\n",
       "      <th>enumcron</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>...</th>\n",
       "      <th>instances</th>\n",
       "      <th>genre</th>\n",
       "      <th>audience</th>\n",
       "      <th>authgender</th>\n",
       "      <th>multiplehtids</th>\n",
       "      <th>comments</th>\n",
       "      <th>coder</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Trimmed</th>\n",
       "      <th>simplegenre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loc.ark+=13960=t5p851b8s</td>\n",
       "      <td>Reid, Stuart J.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lord John Russell</td>\n",
       "      <td>1895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York;Harper &amp; brothers;1</td>\n",
       "      <td>Reid, Stuart J. | Lord John Russell</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>27553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hvd.32044070870779</td>\n",
       "      <td>Smiles, Samuel,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lives of the engineers</td>\n",
       "      <td>1879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;J. Murray;1874-1877.</td>\n",
       "      <td>Smiles, Samuel | Lives of the Engineers</td>\n",
       "      <td>v. 5</td>\n",
       "      <td>27710</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio | short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 people, mixed together (not one per chapter)</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdp.39015005892362</td>\n",
       "      <td>Cruttwell, Maud.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luca Signorelli</td>\n",
       "      <td>1899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;G. Bell &amp; sons;1899.</td>\n",
       "      <td>Cruttwell, Maud | Luca Signorelli</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>27759</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdp.39015051108531</td>\n",
       "      <td>Bettany, George Thomas,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Life of Charles Darwin</td>\n",
       "      <td>1887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;W. Scott;1887.</td>\n",
       "      <td>Bettany, George Thomas | Life of Charles Darwin</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>28380</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loc.ark+=13960=t6b27z54n</td>\n",
       "      <td>Gay, Sydney Howard,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James Madison</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston;New York;Houghton, Mi</td>\n",
       "      <td>Gay, Sydney Howard | James Madison</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>28992</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid                   author authordate  \\\n",
       "0  loc.ark+=13960=t5p851b8s          Reid, Stuart J.        NaN   \n",
       "1        hvd.32044070870779          Smiles, Samuel,        NaN   \n",
       "2        mdp.39015005892362         Cruttwell, Maud.        NaN   \n",
       "3        mdp.39015051108531  Bettany, George Thomas,        NaN   \n",
       "4  loc.ark+=13960=t6b27z54n      Gay, Sydney Howard,        NaN   \n",
       "\n",
       "                    title  latestcomp  hathidate  \\\n",
       "0       Lord John Russell        1895        NaN   \n",
       "1  Lives of the engineers        1879        NaN   \n",
       "2         Luca Signorelli        1899        NaN   \n",
       "3  Life of Charles Darwin        1887        NaN   \n",
       "4           James Madison        1889        NaN   \n",
       "\n",
       "                        imprint  \\\n",
       "0  New York;Harper & brothers;1   \n",
       "1   London;J. Murray;1874-1877.   \n",
       "2   London;G. Bell & sons;1899.   \n",
       "3         London;W. Scott;1887.   \n",
       "4  Boston;New York;Houghton, Mi   \n",
       "\n",
       "                                       gutenstring enumcron gbindex  ...  \\\n",
       "0              Reid, Stuart J. | Lord John Russell  <blank>   27553  ...   \n",
       "1          Smiles, Samuel | Lives of the Engineers     v. 5   27710  ...   \n",
       "2                Cruttwell, Maud | Luca Signorelli  <blank>   27759  ...   \n",
       "3  Bettany, George Thomas | Life of Charles Darwin  <blank>   28380  ...   \n",
       "4               Gay, Sydney Howard | James Madison  <blank>   28992  ...   \n",
       "\n",
       "   instances        genre audience authgender multiplehtids  \\\n",
       "0        NaN          bio      NaN          u           NaN   \n",
       "1        NaN  bio | short      NaN          m           NaN   \n",
       "2        NaN          bio      NaN          f           NaN   \n",
       "3        NaN          bio      NaN          m           NaN   \n",
       "4        NaN          bio      NaN          u           NaN   \n",
       "\n",
       "                                         comments   coder           Folder  \\\n",
       "0                                             NaN  morgan  gutenbiotrimmed   \n",
       "1  2 people, mixed together (not one per chapter)  morgan  gutenbiotrimmed   \n",
       "2                                             NaN  morgan  gutenbiotrimmed   \n",
       "3                                             NaN  morgan  gutenbiotrimmed   \n",
       "4                                             NaN  morgan  gutenbiotrimmed   \n",
       "\n",
       "   Trimmed simplegenre  \n",
       "0  Trimmed         bio  \n",
       "1  Trimmed         bio  \n",
       "2  Trimmed         bio  \n",
       "3  Trimmed         bio  \n",
       "4  Trimmed         bio  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volmeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanfiles = [x for x in os.listdir(r'C:\\Users\\Owner\\Box Sync\\NEHproject\\cleannarratives')\n",
    "              if x.endswith('.txt')]\n",
    "dirtyfiles = [x for x in os.listdir(r'C:\\Users\\Owner\\Box Sync\\NEHproject\\dirtynarratives')\n",
    "               if x.endswith('.txt')]\n",
    "#note different syntax for PC -- getting files from a synced Box folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2489 clean chunks, and\n",
      "2610  dirty ones.\n"
     ]
    }
   ],
   "source": [
    "print(\"We have \" + str(len(cleanfiles)) + \" clean chunks, and\")\n",
    "print(str(len(dirtyfiles)), \" dirty ones.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1079_0.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gbindex(filename):\n",
    "    return filename.split('_')[0]\n",
    "\n",
    "gbdict = dict()\n",
    "\n",
    "for filename in dirtyfiles:\n",
    "    gbindex = get_gbindex(filename)\n",
    "    if gbindex not in gbdict:\n",
    "        gbdict[gbindex] = []\n",
    "    gbdict[gbindex].append(filename)\n",
    "\n",
    "gbset = set(gbdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 423 separate clean volumes that have been chunked.\n"
     ]
    }
   ],
   "source": [
    "print(\"We have \" + str(len(gbset)) + \" separate clean volumes that have been chunked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>author</th>\n",
       "      <th>authordate</th>\n",
       "      <th>title</th>\n",
       "      <th>latestcomp</th>\n",
       "      <th>hathidate</th>\n",
       "      <th>imprint</th>\n",
       "      <th>gutenstring</th>\n",
       "      <th>enumcron</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>...</th>\n",
       "      <th>instances</th>\n",
       "      <th>genre</th>\n",
       "      <th>audience</th>\n",
       "      <th>authgender</th>\n",
       "      <th>multiplehtids</th>\n",
       "      <th>comments</th>\n",
       "      <th>coder</th>\n",
       "      <th>Folder</th>\n",
       "      <th>Trimmed</th>\n",
       "      <th>simplegenre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loc.ark+=13960=t5p851b8s</td>\n",
       "      <td>Reid, Stuart J.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lord John Russell</td>\n",
       "      <td>1895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York;Harper &amp; brothers;1</td>\n",
       "      <td>Reid, Stuart J. | Lord John Russell</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>27553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdp.39015005892362</td>\n",
       "      <td>Cruttwell, Maud.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luca Signorelli</td>\n",
       "      <td>1899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;G. Bell &amp; sons;1899.</td>\n",
       "      <td>Cruttwell, Maud | Luca Signorelli</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>27759</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdp.39015051108531</td>\n",
       "      <td>Bettany, George Thomas,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Life of Charles Darwin</td>\n",
       "      <td>1887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London;W. Scott;1887.</td>\n",
       "      <td>Bettany, George Thomas | Life of Charles Darwin</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>28380</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loc.ark+=13960=t6b27z54n</td>\n",
       "      <td>Gay, Sydney Howard,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>James Madison</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston;New York;Houghton, Mi</td>\n",
       "      <td>Gay, Sydney Howard | James Madison</td>\n",
       "      <td>&lt;blank&gt;</td>\n",
       "      <td>28992</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>morgan</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uc2.ark+=13960=t27944x8r</td>\n",
       "      <td>Marrs, William Taylor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confessions of a neurasthenic</td>\n",
       "      <td>1908</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>Philadelphia;F. A. Davis com</td>\n",
       "      <td>Marrs, William Taylor | Confessions of a Neura...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30487</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peizhen</td>\n",
       "      <td>gutenbiotrimmed</td>\n",
       "      <td>Trimmed</td>\n",
       "      <td>bio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid                   author authordate  \\\n",
       "0  loc.ark+=13960=t5p851b8s          Reid, Stuart J.        NaN   \n",
       "2        mdp.39015005892362         Cruttwell, Maud.        NaN   \n",
       "3        mdp.39015051108531  Bettany, George Thomas,        NaN   \n",
       "4  loc.ark+=13960=t6b27z54n      Gay, Sydney Howard,        NaN   \n",
       "5  uc2.ark+=13960=t27944x8r    Marrs, William Taylor        NaN   \n",
       "\n",
       "                           title  latestcomp  hathidate  \\\n",
       "0              Lord John Russell        1895        NaN   \n",
       "2                Luca Signorelli        1899        NaN   \n",
       "3         Life of Charles Darwin        1887        NaN   \n",
       "4                  James Madison        1889        NaN   \n",
       "5  Confessions of a neurasthenic        1908     1908.0   \n",
       "\n",
       "                        imprint  \\\n",
       "0  New York;Harper & brothers;1   \n",
       "2   London;G. Bell & sons;1899.   \n",
       "3         London;W. Scott;1887.   \n",
       "4  Boston;New York;Houghton, Mi   \n",
       "5  Philadelphia;F. A. Davis com   \n",
       "\n",
       "                                         gutenstring enumcron gbindex  ...  \\\n",
       "0                Reid, Stuart J. | Lord John Russell  <blank>   27553  ...   \n",
       "2                  Cruttwell, Maud | Luca Signorelli  <blank>   27759  ...   \n",
       "3    Bettany, George Thomas | Life of Charles Darwin  <blank>   28380  ...   \n",
       "4                 Gay, Sydney Howard | James Madison  <blank>   28992  ...   \n",
       "5  Marrs, William Taylor | Confessions of a Neura...      NaN   30487  ...   \n",
       "\n",
       "   instances  genre audience authgender multiplehtids  comments    coder  \\\n",
       "0        NaN    bio      NaN          u           NaN       NaN   morgan   \n",
       "2        NaN    bio      NaN          f           NaN       NaN   morgan   \n",
       "3        NaN    bio      NaN          m           NaN       NaN   morgan   \n",
       "4        NaN    bio      NaN          u           NaN       NaN   morgan   \n",
       "5        1.0    bio      NaN          m           NaN       NaN  peizhen   \n",
       "\n",
       "            Folder  Trimmed simplegenre  \n",
       "0  gutenbiotrimmed  Trimmed         bio  \n",
       "2  gutenbiotrimmed  Trimmed         bio  \n",
       "3  gutenbiotrimmed  Trimmed         bio  \n",
       "4  gutenbiotrimmed  Trimmed         bio  \n",
       "5  gutenbiotrimmed  Trimmed         bio  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourtitles = volmeta.loc[volmeta['gbindex'].isin(gbset), : ]\n",
    "ourtitles.shape\n",
    "ourtitles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smaller class has  121  volumes.\n"
     ]
    }
   ],
   "source": [
    "indexes_f = ourtitles.loc[ourtitles.simplegenre == 'fic', : ].index.tolist()\n",
    "indexes_b = ourtitles.loc[ourtitles.simplegenre == 'bio', : ].index.tolist()\n",
    "print('The smaller class has ', len(indexes_b), ' volumes.')\n",
    "\n",
    "# note -- we have less bios than female-authored texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_medians(smaller_indexes, larger_indexes, metadata):\n",
    "    '''\n",
    "    smaller_indexes = indexes of metadata for the smaller class\n",
    "    larger_indexes = indexes of metadata for the larger class\n",
    "    '''\n",
    "    selected_from_large = []\n",
    "    smaller_median = np.median(metadata.loc[smaller_indexes, 'latestcomp'])\n",
    "    \n",
    "    largerdf = metadata.loc[larger_indexes, : ]\n",
    "    above_median = largerdf.loc[largerdf['latestcomp'] >= smaller_median, : ].index.tolist()\n",
    "    below_median = largerdf.loc[largerdf['latestcomp'] <= smaller_median, : ].index.tolist()\n",
    "    \n",
    "    for i in range(len(smaller_indexes)):\n",
    "        if len(selected_from_large) > 0:\n",
    "            larger_median = np.median(metadata.loc[selected_from_large, 'latestcomp'])\n",
    "        else:\n",
    "            larger_median = smaller_median\n",
    "        \n",
    "        if larger_median >= smaller_median and len(below_median) > 0:\n",
    "            selected = random.sample(below_median, 1)[0]\n",
    "            below_median.pop(below_median.index(selected))\n",
    "            selected_from_large.append(selected)\n",
    "        elif larger_median <= smaller_median and len(above_median) > 0:\n",
    "            selected = random.sample(above_median, 1)[0]\n",
    "            above_median.pop(above_median.index(selected))\n",
    "            selected_from_large.append(selected)\n",
    "        else:\n",
    "            # we have no more items that won't distort the median\n",
    "            break\n",
    "\n",
    "    return selected_from_large, smaller_median, larger_median\n",
    "\n",
    "selected_f, median_b, median_f = match_medians(indexes_b, indexes_f, ourtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1889.0 1888.5 121\n"
     ]
    }
   ],
   "source": [
    "print(median_b, median_f, len(selected_f))\n",
    "#121 fiction texts selected to match the 121 total bio texts available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_selected_vols = indexes_b + selected_f\n",
    "len(all_selected_vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_gbindexes = ourtitles.loc[all_selected_vols, 'gbindex']\n",
    "#lock our 242 texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunkframe(filelist, volmeta):\n",
    "    \n",
    "    chunkids = []\n",
    "    gbindices = []\n",
    "    \n",
    "    for filename in filelist:\n",
    "        chunkids.append(filename.replace('.txt', ''))\n",
    "        gbindices.append(get_gbindex(filename))\n",
    "    \n",
    "    df = pd.DataFrame({'chunkid': chunkids, 'gbindex': gbindices})\n",
    "    \n",
    "    chunkmeta = df.merge(volmeta, how = 'inner', on = 'gbindex')\n",
    "    \n",
    "    return chunkmeta\n",
    "#row for each chunk, plus the matching metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2489, 26)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanmeta = create_chunkframe(cleanfiles, ourtitles)\n",
    "cleanmeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2610, 26)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirtymeta = create_chunkframe(dirtyfiles, ourtitles)\n",
    "dirtymeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367, 26)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanmodelmeta = cleanmeta.loc[cleanmeta['gbindex'].isin(selected_gbindexes), : ]\n",
    "cleanmodelmeta.shape\n",
    "#selecting just the chunks from the vols we selected (to match dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 26)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirtymodelmeta = dirtymeta.loc[dirtymeta['gbindex'].isin(selected_gbindexes), : ]\n",
    "dirtymodelmeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doc-Term matrixes \n",
    "\n",
    "clean_rootdir = r'C:\\Users\\Owner\\Box Sync\\NEHproject\\cleannarratives/'\n",
    "\n",
    "clean_paths = []\n",
    "\n",
    "for chunk_id in cleanmodelmeta['chunkid']:\n",
    "    clean_paths.append(clean_rootdir + chunk_id + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zone</th>\n",
       "      <th>æsthetic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chunkid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11030_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         000  10  100  101  102  103  104  105  107  108  ...  zeal  zealand  \\\n",
       "chunkid                                                   ...                  \n",
       "11030_0    0   0    0    0    0    0    0    0    0    0  ...     0        0   \n",
       "11030_1    0   0    0    0    0    0    0    0    0    0  ...     0        0   \n",
       "11030_2    0   0    0    0    0    0    0    0    0    0  ...     0        0   \n",
       "11030_3    0   0    0    0    0    0    0    0    0    0  ...     0        0   \n",
       "11030_4    0   0    0    0    0    0    0    0    0    0  ...     0        0   \n",
       "\n",
       "         zealous  zealously  zenith  zero  zest  zigzag  zone  æsthetic  \n",
       "chunkid                                                                  \n",
       "11030_0        0          0       0     0     0       0     0         0  \n",
       "11030_1        0          0       0     0     0       0     0         0  \n",
       "11030_2        0          0       0     0     0       0     0         0  \n",
       "11030_3        0          0       0     0     0       0     0         0  \n",
       "11030_4        0          0       0     0     0       0     0         0  \n",
       "\n",
       "[5 rows x 17665 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_model_chunk_ids = cleanmodelmeta['chunkid']\n",
    "\n",
    "vectorizer = CountVectorizer(input = 'filename', min_df = .02)\n",
    "sparse_clean_counts = vectorizer.fit_transform(clean_paths) # the vectorizer produces something\n",
    "                                                               # called a 'sparse matrix'; we need to\n",
    "                                                               # unpack it\n",
    "clean_wordcounts = pd.DataFrame(sparse_clean_counts.toarray(), index = clean_model_chunk_ids, \n",
    "                            columns = vectorizer.get_feature_names()) #matching with actual words\n",
    "clean_wordcounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>...</th>\n",
       "      <th>ſurpriſed</th>\n",
       "      <th>ſurpriſing</th>\n",
       "      <th>ſurrounded</th>\n",
       "      <th>ſuſpect</th>\n",
       "      <th>ſuſpected</th>\n",
       "      <th>ſuſpicion</th>\n",
       "      <th>ſwear</th>\n",
       "      <th>ſweet</th>\n",
       "      <th>ſwore</th>\n",
       "      <th>ſº</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chunkid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11030_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00  000  01  05  10  100  101  102  103  104  ...  ſurpriſed  \\\n",
       "chunkid                                                ...              \n",
       "11030_0   0    0   0   0   0    0    0    0    0    0  ...          0   \n",
       "11030_1   0    0   0   0   0    0    0    0    1    1  ...          0   \n",
       "11030_2   0    0   0   0   2    0    0    0    0    0  ...          0   \n",
       "11030_3   0    0   0   0   0    0    0    0    0    0  ...          0   \n",
       "11030_4   0    0   0   0   0    0    0    0    0    0  ...          0   \n",
       "\n",
       "         ſurpriſing  ſurrounded  ſuſpect  ſuſpected  ſuſpicion  ſwear  ſweet  \\\n",
       "chunkid                                                                        \n",
       "11030_0           0           0        0          0          0      0      0   \n",
       "11030_1           0           0        0          0          0      0      0   \n",
       "11030_2           0           0        0          0          0      0      0   \n",
       "11030_3           0           0        0          0          0      0      0   \n",
       "11030_4           0           0        0          0          0      0      0   \n",
       "\n",
       "         ſwore  ſº  \n",
       "chunkid             \n",
       "11030_0      0   0  \n",
       "11030_1      0   0  \n",
       "11030_2      0   0  \n",
       "11030_3      0   0  \n",
       "11030_4      0   0  \n",
       "\n",
       "[5 rows x 20386 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_rootdir = r'C:\\Users\\Owner\\Box Sync\\NEHproject\\dirtynarratives/'\n",
    "\n",
    "dirty_paths = []\n",
    "\n",
    "for chunk_id in dirtymodelmeta['chunkid']:\n",
    "    dirty_paths.append(dirty_rootdir + chunk_id + '.txt')\n",
    "\n",
    "dirty_model_chunk_ids = dirtymodelmeta['chunkid']\n",
    "    \n",
    "vectorizer = CountVectorizer(input = 'filename', min_df = .02)\n",
    "sparse_dirty_counts = vectorizer.fit_transform(dirty_paths) \n",
    "dirty_wordcounts = pd.DataFrame(sparse_dirty_counts.toarray(), index = dirty_model_chunk_ids, \n",
    "                            columns = vectorizer.get_feature_names())\n",
    "dirty_wordcounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing/weighting wordcounts \n",
    "clean_rowsums = clean_wordcounts.sum(axis = 'columns')\n",
    "clean_freqs = clean_wordcounts.divide(clean_rowsums, axis = 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_rowsums = dirty_wordcounts.sum(axis = 'columns')\n",
    "dirty_freqs = dirty_wordcounts.divide(dirty_rowsums, axis = 'rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>...</th>\n",
       "      <th>ſurpriſed</th>\n",
       "      <th>ſurpriſing</th>\n",
       "      <th>ſurrounded</th>\n",
       "      <th>ſuſpect</th>\n",
       "      <th>ſuſpected</th>\n",
       "      <th>ſuſpicion</th>\n",
       "      <th>ſwear</th>\n",
       "      <th>ſweet</th>\n",
       "      <th>ſwore</th>\n",
       "      <th>ſº</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chunkid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11030_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20386 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          00  000   01   05        10  100  101  102       103       104  ...  \\\n",
       "chunkid                                                                   ...   \n",
       "11030_0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...   \n",
       "11030_1  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000075  0.000075  ...   \n",
       "11030_2  0.0  0.0  0.0  0.0  0.000147  0.0  0.0  0.0  0.000000  0.000000  ...   \n",
       "11030_3  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...   \n",
       "11030_4  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.000000  ...   \n",
       "\n",
       "         ſurpriſed  ſurpriſing  ſurrounded  ſuſpect  ſuſpected  ſuſpicion  \\\n",
       "chunkid                                                                     \n",
       "11030_0        0.0         0.0         0.0      0.0        0.0        0.0   \n",
       "11030_1        0.0         0.0         0.0      0.0        0.0        0.0   \n",
       "11030_2        0.0         0.0         0.0      0.0        0.0        0.0   \n",
       "11030_3        0.0         0.0         0.0      0.0        0.0        0.0   \n",
       "11030_4        0.0         0.0         0.0      0.0        0.0        0.0   \n",
       "\n",
       "         ſwear  ſweet  ſwore   ſº  \n",
       "chunkid                            \n",
       "11030_0    0.0    0.0    0.0  0.0  \n",
       "11030_1    0.0    0.0    0.0  0.0  \n",
       "11030_2    0.0    0.0    0.0  0.0  \n",
       "11030_3    0.0    0.0    0.0  0.0  \n",
       "11030_4    0.0    0.0    0.0  0.0  \n",
       "\n",
       "[5 rows x 20386 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_freqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating training and testing data (same volumes)\n",
    "selected_authors = list(set(volmeta.loc[volmeta['gbindex'].isin(selected_gbindexes), 'author']))\n",
    "random.shuffle(selected_authors)\n",
    "threequarters = int(len(selected_authors) * .75)\n",
    "trainauthors = selected_authors[0 : threequarters]\n",
    "testauthors = selected_authors[threequarters: ]\n",
    "\n",
    "cleantrain = cleanmodelmeta.loc[cleanmodelmeta['author'].isin(trainauthors), : ]\n",
    "cleantest = cleanmodelmeta.loc[cleanmodelmeta['author'].isin(testauthors), : ]\n",
    "cleantrain_freqs = clean_freqs.loc[cleantrain.chunkid]\n",
    "cleantest_freqs = clean_freqs.loc[cleantest.chunkid]\n",
    "\n",
    "dirtytrain = dirtymodelmeta.loc[dirtymodelmeta['author'].isin(trainauthors), : ]\n",
    "dirtytest = dirtymodelmeta.loc[dirtymodelmeta['author'].isin(testauthors), : ]\n",
    "dirtytrain_freqs = dirty_freqs.loc[dirtytrain.chunkid]\n",
    "dirtytest_freqs = dirty_freqs.loc[dirtytest.chunkid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean training set:  (1049, 26)\n",
      "Clean test set:  (318, 26)\n",
      "Hathi training set:  (1093, 26)\n",
      "Hathi testing set:  (333, 26)\n"
     ]
    }
   ],
   "source": [
    "print('Clean training set: ', cleantrain.shape)\n",
    "print('Clean test set: ', cleantest.shape)\n",
    "print('Hathi training set: ', dirtytrain.shape)\n",
    "print('Hathi testing set: ', dirtytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are there consistently more Hathi chunks b/c of the extra text/notes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1426, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1426, 26)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connecting with our metadata for info later\n",
    "\n",
    "dirtymodelmeta.set_index('chunkid', inplace = True)\n",
    "print(dirtymodelmeta.shape)\n",
    "dirty_ids_order = np.append(list(dirtytrain.chunkid), list(dirtytest.chunkid))\n",
    "dirtymodelmeta = dirtymodelmeta.loc[dirty_ids_order, : ]\n",
    "dirtymodelmeta.reset_index(inplace = True)\n",
    "dirtymodelmeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1367, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1367, 26)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanmodelmeta.set_index('chunkid', inplace = True)\n",
    "print(cleanmodelmeta.shape)\n",
    "clean_ids_order = np.append(list(cleantrain.chunkid), list(cleantest.chunkid))\n",
    "cleanmodelmeta = cleanmodelmeta.loc[clean_ids_order, : ]\n",
    "cleanmodelmeta.reset_index(inplace = True)\n",
    "cleanmodelmeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model time! Outer loop = num of features, inner loop = regulariz. constant\n",
    "#Starting with clean texts \n",
    "def get_doc_freqs(X, y):\n",
    "    return np.count_nonzero(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 10000 0.8505811403508773\n",
      "1000 3000 0.8589254385964914\n",
      "1000 1000 0.8589035087719299\n",
      "1000 500 0.8578728070175439\n",
      "1000 100 0.8599671052631578\n",
      "1000 10 0.8610087719298246\n",
      "1000 1 0.8610197368421053\n",
      "1000 0.1 0.8683552631578948\n",
      "1000 0.01 0.8704495614035087\n",
      "1000 0.001 0.8746820175438597\n",
      "1000 0.0001 0.854813596491228\n",
      "1500 10000 0.8829714912280702\n",
      "1500 3000 0.8798464912280701\n",
      "1500 1000 0.8798464912280701\n",
      "1500 500 0.8787938596491228\n",
      "1500 100 0.8808771929824563\n",
      "1500 10 0.8819298245614036\n",
      "1500 1 0.880888157894737\n",
      "1500 0.1 0.8850548245614036\n",
      "1500 0.01 0.885076754385965\n",
      "1500 0.001 0.8830043859649124\n",
      "1500 0.0001 0.8579276315789472\n",
      "2000 10000 0.8902741228070175\n",
      "2000 3000 0.8881907894736842\n",
      "2000 1000 0.8860964912280702\n",
      "2000 500 0.8829605263157895\n",
      "2000 100 0.8840021929824561\n",
      "2000 10 0.8850438596491228\n",
      "2000 1 0.8850438596491228\n",
      "2000 0.1 0.8839912280701754\n",
      "2000 0.01 0.8829605263157895\n",
      "2000 0.001 0.8850548245614036\n",
      "2000 0.0001 0.8621052631578948\n",
      "2500 10000 0.8924013157894738\n",
      "2500 3000 0.8892543859649124\n",
      "2500 1000 0.8850657894736843\n",
      "2500 500 0.8861184210526316\n",
      "2500 100 0.885076754385965\n",
      "2500 10 0.8850657894736843\n",
      "2500 1 0.8861074561403509\n",
      "2500 0.1 0.8850548245614036\n",
      "2500 0.01 0.8860855263157894\n",
      "2500 0.001 0.8850548245614036\n",
      "2500 0.0001 0.8662719298245614\n",
      "3000 10000 0.8881907894736841\n",
      "3000 3000 0.8881907894736841\n",
      "3000 1000 0.8829824561403509\n",
      "3000 500 0.8829934210526316\n",
      "3000 100 0.8829934210526316\n",
      "3000 10 0.8829934210526316\n",
      "3000 1 0.8829934210526316\n",
      "3000 0.1 0.8829824561403509\n",
      "3000 0.01 0.8819298245614036\n",
      "3000 0.001 0.8871600877192982\n",
      "3000 0.0001 0.8683771929824561\n",
      "3500 10000 0.8871710526315789\n",
      "3500 3000 0.8882127192982455\n",
      "3500 1000 0.8829934210526316\n",
      "3500 500 0.881951754385965\n",
      "3500 100 0.8788157894736843\n",
      "3500 10 0.8798574561403509\n",
      "3500 1 0.8788157894736843\n",
      "3500 0.1 0.8809100877192982\n",
      "3500 0.01 0.8840241228070175\n",
      "3500 0.001 0.8871491228070175\n",
      "3500 0.0001 0.8683442982456141\n",
      "4000 10000 0.8871600877192982\n",
      "4000 3000 0.8850657894736843\n",
      "4000 1000 0.8829824561403509\n",
      "4000 500 0.8850548245614036\n",
      "4000 100 0.8829714912280702\n",
      "4000 10 0.8808771929824563\n",
      "4000 1 0.8808662280701756\n",
      "4000 0.1 0.8829495614035088\n",
      "4000 0.01 0.8850328947368421\n",
      "4000 0.001 0.8850109649122807\n",
      "4000 0.0001 0.8756578947368421\n",
      "4500 10000 0.8819188596491229\n",
      "4500 3000 0.8850548245614036\n",
      "4500 1000 0.8798355263157894\n",
      "4500 500 0.8808771929824563\n",
      "4500 100 0.8787828947368421\n",
      "4500 10 0.8819298245614036\n",
      "4500 1 0.8808771929824563\n",
      "4500 0.1 0.8798245614035087\n",
      "4500 0.01 0.879813596491228\n",
      "4500 0.001 0.8797916666666667\n",
      "4500 0.0001 0.8777302631578948\n",
      "5000 10000 0.8933991228070175\n",
      "5000 3000 0.894451754385965\n",
      "5000 1000 0.8871600877192982\n",
      "5000 500 0.8861184210526316\n",
      "5000 100 0.8871600877192982\n",
      "5000 10 0.8871491228070175\n",
      "5000 1 0.8871381578947369\n",
      "5000 0.1 0.8871381578947369\n",
      "5000 0.01 0.8840131578947368\n",
      "5000 0.001 0.881875\n",
      "5000 0.0001 0.8829605263157895\n",
      "5500 10000 0.8923464912280702\n",
      "5500 3000 0.8923464912280702\n",
      "5500 1000 0.8860855263157894\n",
      "5500 500 0.8850219298245614\n",
      "5500 100 0.8881688596491228\n",
      "5500 10 0.8892105263157895\n",
      "5500 1 0.8902631578947368\n",
      "5500 0.1 0.8902631578947368\n",
      "5500 0.01 0.890263157894737\n",
      "5500 0.001 0.8881578947368421\n",
      "5500 0.0001 0.8850438596491228\n",
      "6000 10000 0.8965350877192982\n",
      "6000 3000 0.8975877192982455\n",
      "6000 1000 0.8923684210526316\n",
      "6000 500 0.8913157894736841\n",
      "6000 100 0.8902741228070175\n",
      "6000 10 0.8902741228070175\n",
      "6000 1 0.8902741228070177\n",
      "6000 0.1 0.8892214912280704\n",
      "6000 0.01 0.8881688596491228\n",
      "6000 0.001 0.8902521929824561\n",
      "6000 0.0001 0.8829276315789473\n",
      "7000 10000 0.891293859649123\n",
      "7000 3000 0.891293859649123\n",
      "7000 1000 0.8850328947368423\n",
      "7000 500 0.8860635964912282\n",
      "7000 100 0.8871271929824562\n",
      "7000 10 0.8839912280701755\n",
      "7000 1 0.8850328947368421\n",
      "7000 0.1 0.8892214912280701\n",
      "7000 0.01 0.891326754385965\n",
      "7000 0.001 0.885032894736842\n",
      "7000 0.0001 0.8850328947368421\n"
     ]
    }
   ],
   "source": [
    "resultarray = []\n",
    "\n",
    "featureoptions = [1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 7000]\n",
    "c_options = [10000, 3000, 1000, 500, 100, 10, 1, .1, .01, .001, .0001]\n",
    "\n",
    "for featurecount in featureoptions:\n",
    "    docfreqs = []\n",
    "    for col in cleantrain_freqs.columns:\n",
    "        docfreqs.append((sum(cleantrain_freqs[col] > 0), col))\n",
    "    docfreqs.sort()\n",
    "    features = [x[1] for x in docfreqs[-featurecount : ]] # because sorted in ascending order\n",
    "    \n",
    "    model_features = cleantrain_freqs.loc[ : , features]\n",
    "    \n",
    "    resultrow = []\n",
    "    \n",
    "    for c_param in c_options:\n",
    "        logreg = LogisticRegression(C = c_param, max_iter = 2000)\n",
    "        scaler = StandardScaler()\n",
    "        # feature_selector = SelectKBest(get_doc_freqs, k = featurecount)\n",
    "        pipe = Pipeline([\n",
    "            # ('fkb', feature_selector),\n",
    "            ('sc', scaler),\n",
    "            ('lr', logreg)\n",
    "        ])    \n",
    "        grouper = GroupKFold(n_splits = 10)\n",
    "        cv_results = cross_validate(estimator = pipe, \n",
    "                                    X = model_features,\n",
    "                                    y = cleantrain['simplegenre'], \n",
    "                                    groups = cleantrain['author'], \n",
    "                                    cv = grouper)\n",
    "        mean_score = np.mean(cv_results['test_score'])\n",
    "        print(featurecount, c_param, mean_score)\n",
    "        resultrow.append(mean_score)\n",
    "    \n",
    "    resultarray.append(resultrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultarray = np.array(resultarray)\n",
    "thearrayshape = resultarray.shape\n",
    "resarray = rankdata(resultarray).reshape(thearrayshape)   \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.imshow(resarray, cmap='hot', aspect = 'auto')\n",
    "plt.yticks(ticks = [x for x in range(len(featureoptions))], labels = featureoptions)\n",
    "thexlabels = [str(x) for x in c_options]\n",
    "thexlabels[0] = '10^4'\n",
    "plt.xticks(ticks = [x for x in range(len(c_options))], labels = thexlabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 3000\n"
     ]
    }
   ],
   "source": [
    "maxtuple = np.where(resarray == np.amax(resarray))\n",
    "print(featureoptions[maxtuple[0][0]], c_options[maxtuple[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = GroupKFold(n_splits = 10)\n",
    "\n",
    "docfreqs = []\n",
    "for col in clean_wordcounts.columns:\n",
    "    docfreqs.append((sum(clean_wordcounts[col] > 0), col))\n",
    "docfreqs.sort()\n",
    "features = [x[1] for x in docfreqs[-2000: ]] #because sorted ascending\n",
    "\n",
    "train_features = cleantrain_freqs.loc[ : , features]  \n",
    "    \n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "bestmodel = LogisticRegression(C = .001, max_iter = 2000)\n",
    "cleantrain_probabilities = cross_val_predict(bestmodel, train_features, cleantrain['simplegenre'], \n",
    "                                     groups = cleantrain['author'], cv = grouper,\n",
    "                                    method = 'predict_proba')\n",
    "\n",
    "## NOW APPLY THE SAME SCALER AND MODEL TO TEST SET\n",
    "\n",
    "bestmodel = LogisticRegression(C = .001, max_iter = 2000)\n",
    "bestmodel.fit(train_features, cleantrain['simplegenre'])\n",
    "\n",
    "test_features = cleantest_freqs.loc[ : , features] \n",
    "test_features = scaler.transform(test_features) # Note this is the same scaler we fit\n",
    "                                                # to train features; we DON'T fit a new one to the\n",
    "                                                # test features. We deliberately blind ourselves to that\n",
    "                                                # information.\n",
    "\n",
    "cleantest_predictions = bestmodel.predict(test_features)\n",
    "cleantest_probabilities = bestmodel.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308176100628931"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cleantest_predictions == cleantest['simplegenre']) / len(cleantest['simplegenre'])\n",
    "\n",
    "#quite accurate on the clean texts! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 100000 0.8363792118789263\n",
      "1000 10000 0.8402912621359222\n",
      "1000 3000 0.8393108699790597\n",
      "1000 1000 0.8402912621359224\n",
      "1000 500 0.8412716542927852\n",
      "1000 100 0.8422520464496477\n",
      "1000 10 0.8442128307633732\n",
      "1000 1 0.8471444888635066\n",
      "1000 0.1 0.853017323434228\n",
      "1000 0.01 0.8579097658480869\n",
      "1000 0.001 0.8657529031029888\n",
      "1000 0.0001 0.8491052731772321\n",
      "1500 100000 0.8637826004188083\n",
      "1500 10000 0.8667237768893965\n",
      "1500 3000 0.8677041690462592\n",
      "1500 1000 0.872606129830573\n",
      "1500 500 0.8735865219874357\n",
      "1500 100 0.8755473063011612\n",
      "1500 10 0.8765276984580239\n",
      "1500 1 0.8735865219874357\n",
      "1500 0.1 0.8735865219874357\n",
      "1500 0.01 0.8765276984580239\n",
      "1500 0.001 0.8784884827717494\n",
      "1500 0.0001 0.8520559680182753\n",
      "2000 100000 0.8775176089853417\n",
      "2000 10000 0.8784884827717494\n",
      "2000 3000 0.8784884827717496\n",
      "2000 1000 0.8794688749286121\n",
      "2000 500 0.8794688749286121\n",
      "2000 100 0.8794688749286121\n",
      "2000 10 0.8784884827717494\n",
      "2000 1 0.8775080906148867\n",
      "2000 0.1 0.8784884827717494\n",
      "2000 0.01 0.8824100513992004\n",
      "2000 0.001 0.8774890538739768\n",
      "2000 0.0001 0.8579288025889967\n",
      "2500 100000 0.8755568246716162\n",
      "2500 10000 0.8735960403578907\n",
      "2500 3000 0.876537216828479\n",
      "2500 1000 0.8745764325147535\n",
      "2500 500 0.876537216828479\n",
      "2500 100 0.8775176089853417\n",
      "2500 10 0.8735960403578907\n",
      "2500 1 0.8745669141442984\n",
      "2500 0.1 0.872606129830573\n",
      "2500 0.01 0.8735865219874357\n",
      "2500 0.001 0.8696649533599847\n",
      "2500 0.0001 0.8539977155910907\n",
      "3000 100000 0.8637730820483533\n",
      "3000 10000 0.8627926898914906\n",
      "3000 3000 0.8657338663620788\n",
      "3000 1000 0.8657338663620788\n",
      "3000 500 0.8696554349895298\n",
      "3000 100 0.8676946506758043\n",
      "3000 10 0.8657338663620788\n",
      "3000 1 0.868675042832667\n",
      "3000 0.1 0.868675042832667\n",
      "3000 0.01 0.8696554349895298\n",
      "3000 0.001 0.8696649533599847\n",
      "3000 0.0001 0.8559584999048162\n",
      "3500 100000 0.8676946506758043\n",
      "3500 10000 0.8686655244622121\n",
      "3500 3000 0.8696459166190749\n",
      "3500 1000 0.8696459166190749\n",
      "3500 500 0.8706263087759376\n",
      "3500 100 0.8716067009328003\n",
      "3500 10 0.868665524462212\n",
      "3500 1 0.8706263087759375\n",
      "3500 0.1 0.8716067009328003\n",
      "3500 0.01 0.8706358271463925\n",
      "3500 0.001 0.8725870930896631\n",
      "3500 0.0001 0.8588901580049495\n",
      "4000 100000 0.8628022082619455\n",
      "4000 10000 0.86084142394822\n",
      "4000 3000 0.8618218161050828\n",
      "4000 1000 0.8637826004188083\n",
      "4000 500 0.8657338663620788\n",
      "4000 100 0.8657338663620788\n",
      "4000 10 0.8657338663620788\n",
      "4000 1 0.8696459166190748\n",
      "4000 0.1 0.8715971825623454\n",
      "4000 0.01 0.8676756139348945\n",
      "4000 0.001 0.8696459166190749\n",
      "4000 0.0001 0.8647534742052161\n",
      "4500 100000 0.8618122977346279\n",
      "4500 10000 0.8618122977346279\n",
      "4500 3000 0.8618122977346279\n",
      "4500 1000 0.8637730820483533\n",
      "4500 500 0.8627831715210356\n",
      "4500 100 0.8637635636778983\n",
      "4500 10 0.8627831715210356\n",
      "4500 1 0.8618027793641728\n",
      "4500 0.1 0.8657243479916238\n",
      "4500 0.01 0.8627736531505807\n",
      "4500 0.001 0.865714829621169\n",
      "4500 0.0001 0.8618218161050828\n",
      "5000 100000 0.868675042832667\n",
      "5000 10000 0.868675042832667\n",
      "5000 3000 0.8667142585189416\n",
      "5000 1000 0.8667237768893965\n",
      "5000 500 0.8657433847325338\n",
      "5000 100 0.8647534742052161\n",
      "5000 10 0.8647534742052161\n",
      "5000 1 0.8667142585189416\n",
      "5000 0.1 0.8696554349895298\n",
      "5000 0.01 0.868675042832667\n",
      "5000 0.001 0.8725870930896631\n",
      "5000 0.0001 0.8628212450028554\n",
      "5500 100000 0.868694079573577\n",
      "5500 10000 0.8677136874167143\n",
      "5500 3000 0.868694079573577\n",
      "5500 1000 0.8677136874167143\n",
      "5500 500 0.868684561203122\n",
      "5500 100 0.8647534742052161\n",
      "5500 10 0.8647534742052161\n",
      "5500 1 0.8637730820483533\n",
      "5500 0.1 0.8676946506758043\n",
      "5500 0.01 0.864762992575671\n",
      "5500 0.001 0.8725870930896631\n",
      "5500 0.0001 0.8647820293165809\n",
      "6000 100000 0.868675042832667\n",
      "6000 10000 0.868675042832667\n",
      "6000 3000 0.868675042832667\n",
      "6000 1000 0.8696554349895298\n",
      "6000 500 0.868675042832667\n",
      "6000 100 0.8657433847325338\n",
      "6000 10 0.8677041690462592\n",
      "6000 1 0.8696554349895298\n",
      "6000 0.1 0.8696554349895298\n",
      "6000 0.01 0.8676946506758043\n",
      "6000 0.001 0.8745478774033886\n",
      "6000 0.0001 0.8667428136303064\n",
      "6500 100000 0.8706453455168475\n",
      "6500 10000 0.8706453455168475\n",
      "6500 3000 0.8716257376737102\n",
      "6500 1000 0.8706453455168475\n",
      "6500 500 0.8706453455168475\n",
      "6500 100 0.8696649533599847\n",
      "6500 10 0.8706453455168475\n",
      "6500 1 0.8706453455168475\n",
      "6500 0.1 0.872606129830573\n",
      "6500 0.01 0.868684561203122\n",
      "6500 0.001 0.872596611460118\n",
      "6500 0.0001 0.8667332952598515\n",
      "7000 100000 0.8706548638873025\n",
      "7000 10000 0.8706548638873025\n",
      "7000 3000 0.8696744717304398\n",
      "7000 1000 0.8696744717304398\n",
      "7000 500 0.872606129830573\n",
      "7000 100 0.8716257376737102\n",
      "7000 10 0.8716162193032553\n",
      "7000 1 0.872596611460118\n",
      "7000 0.1 0.8735865219874357\n",
      "7000 0.01 0.8716162193032553\n",
      "7000 0.001 0.8735865219874357\n",
      "7000 0.0001 0.8667332952598515\n"
     ]
    }
   ],
   "source": [
    "#Dirty model time \n",
    "\n",
    "resultarray = []\n",
    "\n",
    "featureoptions = [1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000]\n",
    "c_options = [100000, 10000, 3000, 1000, 500, 100, 10, 1, .1, .01, .001, .0001]\n",
    "\n",
    "for featurecount in featureoptions:\n",
    "    docfreqs = []\n",
    "    for col in dirtytrain_freqs.columns:\n",
    "        docfreqs.append((sum(dirtytrain_freqs[col] > 0), col))\n",
    "    docfreqs.sort()\n",
    "    features = [x[1] for x in docfreqs[-featurecount: ]]  # because sorted ascending\n",
    "    \n",
    "    model_features = dirtytrain_freqs.loc[ : , features]\n",
    "    \n",
    "    resultrow = []\n",
    "    \n",
    "    for c_param in c_options:\n",
    "        logreg = LogisticRegression(C = c_param, max_iter = 2000)\n",
    "        scaler = StandardScaler()\n",
    "        # feature_selector = SelectKBest(get_doc_freqs, k = featurecount)\n",
    "        pipe = Pipeline([\n",
    "            # ('fs', feature_selector),\n",
    "            ('sc', scaler),\n",
    "            ('lr', logreg)\n",
    "        ])\n",
    "        grouper = GroupKFold(n_splits = 10)\n",
    "        cv_results = cross_validate(estimator = pipe, \n",
    "                                    X = model_features, \n",
    "                                    y = dirtytrain['simplegenre'], \n",
    "                                    groups = dirtytrain['author'], \n",
    "                                    cv = grouper)\n",
    "        mean_score = np.mean(cv_results['test_score'])\n",
    "        print(featurecount, c_param, mean_score)\n",
    "        resultrow.append(mean_score)\n",
    "    \n",
    "    resultarray.append(resultrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultarray = np.array(resultarray)\n",
    "thearrayshape = resultarray.shape\n",
    "resarray = rankdata(resultarray).reshape(thearrayshape)   # I'm doing this because otherwise\n",
    "                                                    # fine details at top of range can be hard to see.\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "ax.imshow(resarray, cmap='hot', aspect = 'auto')\n",
    "plt.yticks(ticks = [x for x in range(len(featureoptions))], labels = featureoptions)\n",
    "thexlabels = [str(x) for x in c_options]\n",
    "thexlabels[0] = '10^5'\n",
    "thexlabels[1] = '10^4'\n",
    "plt.xticks(ticks = [x for x in range(len(c_options))], labels = thexlabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 0.01\n"
     ]
    }
   ],
   "source": [
    "maxtuple = np.where(resarray == np.amax(resarray))\n",
    "print(featureoptions[maxtuple[0][0]], c_options[maxtuple[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreqs = []\n",
    "for col in dirtytrain_freqs.columns:\n",
    "    docfreqs.append((sum(dirtytrain_freqs[col] > 0), col))\n",
    "docfreqs.sort()\n",
    "features = [x[1] for x in docfreqs[-2000 : ]]\n",
    "\n",
    "train_features = dirtytrain_freqs.loc[ : , features]\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "bestmodel = LogisticRegression(C = .01, max_iter = 2000)\n",
    "dirtytrain_probabilities = cross_val_predict(bestmodel, train_features, dirtytrain['simplegenre'], \n",
    "                                     groups = dirtytrain['author'], cv = grouper,\n",
    "                                    method = 'predict_proba')\n",
    "\n",
    "## NOW APPLY THE SAME SCALER AND MODEL TO TEST SET\n",
    "\n",
    "bestmodel = LogisticRegression(C = .01, max_iter = 2000)\n",
    "bestmodel.fit(train_features, dirtytrain['simplegenre'])\n",
    "\n",
    "test_features = dirtytest_freqs.loc[ : , features] \n",
    "test_features = scaler.transform(test_features)    # Note this is the same scaler we fit\n",
    "                                                # to train features; we DON'T fit a new one to the\n",
    "                                                # test features. We deliberately blind ourselves to that\n",
    "                                                # information.\n",
    "\n",
    "dirtytest_predictions = bestmodel.predict(test_features)\n",
    "dirtytest_probabilities = bestmodel.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9159159159159159"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sum(dirtytest_predictions == dirtytest['simplegenre']) / len(dirtytest['simplegenre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dirty-texts model is a bit less accurate (92 v 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why is it less accurate to model on Hathi texts? \n",
    "\n",
    "# Predicted vs real \"distance\" (directonal or absolute)\n",
    "\n",
    "dirty_y = dirtymodelmeta['simplegenre'].map({'bio': 1, 'fic': 0})  # we already put this in train-test order\n",
    "                                                            # so it will match the next line\n",
    "dirty_probabilities = np.append(dirtytrain_probabilities[ : , 0], dirtytest_probabilities[ : , 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_error = dirty_y - dirty_probabilities\n",
    "dirty_absolute_error = np.abs(dirty_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_y = cleanmodelmeta['simplegenre'].map({'bio': 1, 'fic': 0})\n",
    "\n",
    "clean_probabilities = np.append(cleantrain_probabilities[ : , 0], cleantest_probabilities[ : , 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_error = clean_y - clean_probabilities\n",
    "clean_absolute_error = np.abs(clean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of average error for vols as a whole (avg the chunks)\n",
    "clean_gbi = [get_gbindex(x) for x in cleanmodelmeta['chunkid']]\n",
    "clean_df = pd.DataFrame({'chunkid': cleanmodelmeta['chunkid'], 'gbindex': clean_gbi,\n",
    "                         'clean_error': clean_error, 'clean_abs_error': clean_absolute_error})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_error</th>\n",
       "      <th>clean_abs_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbindex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40919</th>\n",
       "      <td>0.232118</td>\n",
       "      <td>0.232118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>-0.247688</td>\n",
       "      <td>0.247688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40385</th>\n",
       "      <td>-0.056425</td>\n",
       "      <td>0.056425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41324</th>\n",
       "      <td>0.554383</td>\n",
       "      <td>0.554383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42281</th>\n",
       "      <td>0.102313</td>\n",
       "      <td>0.102313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40205</th>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.226957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28380</th>\n",
       "      <td>0.023274</td>\n",
       "      <td>0.023274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52599</th>\n",
       "      <td>-0.149591</td>\n",
       "      <td>0.149591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37820</th>\n",
       "      <td>-0.265469</td>\n",
       "      <td>0.265469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32424</th>\n",
       "      <td>-0.316611</td>\n",
       "      <td>0.316611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         clean_error  clean_abs_error\n",
       "gbindex                              \n",
       "40919       0.232118         0.232118\n",
       "468        -0.247688         0.247688\n",
       "40385      -0.056425         0.056425\n",
       "41324       0.554383         0.554383\n",
       "42281       0.102313         0.102313\n",
       "40205       0.226957         0.226957\n",
       "28380       0.023274         0.023274\n",
       "52599      -0.149591         0.149591\n",
       "37820      -0.265469         0.265469\n",
       "32424      -0.316611         0.316611"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meandf = clean_df.groupby('gbindex').mean()\n",
    "meandf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_gbi = [get_gbindex(x) for x in dirtymodelmeta['chunkid']]\n",
    "dirty_df = pd.DataFrame({'chunkid': list(dirtymodelmeta['chunkid']), 'gbindex': dirty_gbi,\n",
    "                         'dirty_error': dirty_error, 'dirty_abs_error': dirty_absolute_error})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkid</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>dirty_error</th>\n",
       "      <th>dirty_abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>652_2</td>\n",
       "      <td>652</td>\n",
       "      <td>-0.152706</td>\n",
       "      <td>0.152706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>LennCFQ2fic_3</td>\n",
       "      <td>LennCFQ2fic</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>0.001295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>7777_6</td>\n",
       "      <td>7777</td>\n",
       "      <td>0.067836</td>\n",
       "      <td>0.067836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>33573_0</td>\n",
       "      <td>33573</td>\n",
       "      <td>-0.140319</td>\n",
       "      <td>0.140319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>46651_0</td>\n",
       "      <td>46651</td>\n",
       "      <td>0.044950</td>\n",
       "      <td>0.044950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chunkid      gbindex  dirty_error  dirty_abs_error\n",
       "1001          652_2          652    -0.152706         0.152706\n",
       "1400  LennCFQ2fic_3  LennCFQ2fic    -0.001295         0.001295\n",
       "1025         7777_6         7777     0.067836         0.067836\n",
       "271         33573_0        33573    -0.140319         0.140319\n",
       "753         46651_0        46651     0.044950         0.044950"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkid</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>dirty_error</th>\n",
       "      <th>dirty_abs_error</th>\n",
       "      <th>clean_error</th>\n",
       "      <th>clean_abs_error</th>\n",
       "      <th>error_divergence</th>\n",
       "      <th>divergence_of_abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>36534_4</td>\n",
       "      <td>36534</td>\n",
       "      <td>0.063752</td>\n",
       "      <td>0.063752</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>-0.278580</td>\n",
       "      <td>-0.278580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>WartTLSbio_2</td>\n",
       "      <td>WartTLSbio</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.046287</td>\n",
       "      <td>0.046287</td>\n",
       "      <td>-0.035401</td>\n",
       "      <td>-0.035401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>36928_5</td>\n",
       "      <td>36928</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.105049</td>\n",
       "      <td>0.105049</td>\n",
       "      <td>-0.094970</td>\n",
       "      <td>-0.094970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>41636_9</td>\n",
       "      <td>41636</td>\n",
       "      <td>-0.038097</td>\n",
       "      <td>0.038097</td>\n",
       "      <td>-0.086390</td>\n",
       "      <td>0.086390</td>\n",
       "      <td>0.048292</td>\n",
       "      <td>-0.048292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>51932_5</td>\n",
       "      <td>51932</td>\n",
       "      <td>0.216864</td>\n",
       "      <td>0.216864</td>\n",
       "      <td>0.430285</td>\n",
       "      <td>0.430285</td>\n",
       "      <td>-0.213421</td>\n",
       "      <td>-0.213421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>42857_1</td>\n",
       "      <td>42857</td>\n",
       "      <td>0.153012</td>\n",
       "      <td>0.153012</td>\n",
       "      <td>0.319066</td>\n",
       "      <td>0.319066</td>\n",
       "      <td>-0.166055</td>\n",
       "      <td>-0.166055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>41420_2</td>\n",
       "      <td>41420</td>\n",
       "      <td>-0.036461</td>\n",
       "      <td>0.036461</td>\n",
       "      <td>-0.173601</td>\n",
       "      <td>0.173601</td>\n",
       "      <td>0.137140</td>\n",
       "      <td>-0.137140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>33573_5</td>\n",
       "      <td>33573</td>\n",
       "      <td>-0.039807</td>\n",
       "      <td>0.039807</td>\n",
       "      <td>-0.166749</td>\n",
       "      <td>0.166749</td>\n",
       "      <td>0.126942</td>\n",
       "      <td>-0.126942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>41420_0</td>\n",
       "      <td>41420</td>\n",
       "      <td>-0.051208</td>\n",
       "      <td>0.051208</td>\n",
       "      <td>-0.173601</td>\n",
       "      <td>0.173601</td>\n",
       "      <td>0.122393</td>\n",
       "      <td>-0.122393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>47209_5</td>\n",
       "      <td>47209</td>\n",
       "      <td>0.073598</td>\n",
       "      <td>0.073598</td>\n",
       "      <td>0.178967</td>\n",
       "      <td>0.178967</td>\n",
       "      <td>-0.105368</td>\n",
       "      <td>-0.105368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           chunkid     gbindex  dirty_error  dirty_abs_error  clean_error  \\\n",
       "378        36534_4       36534     0.063752         0.063752     0.342333   \n",
       "1420  WartTLSbio_2  WartTLSbio     0.010887         0.010887     0.046287   \n",
       "392        36928_5       36928     0.010079         0.010079     0.105049   \n",
       "610        41636_9       41636    -0.038097         0.038097    -0.086390   \n",
       "1316       51932_5       51932     0.216864         0.216864     0.430285   \n",
       "1269       42857_1       42857     0.153012         0.153012     0.319066   \n",
       "1265       41420_2       41420    -0.036461         0.036461    -0.173601   \n",
       "276        33573_5       33573    -0.039807         0.039807    -0.166749   \n",
       "1263       41420_0       41420    -0.051208         0.051208    -0.173601   \n",
       "1293       47209_5       47209     0.073598         0.073598     0.178967   \n",
       "\n",
       "      clean_abs_error  error_divergence  divergence_of_abs_error  \n",
       "378          0.342333         -0.278580                -0.278580  \n",
       "1420         0.046287         -0.035401                -0.035401  \n",
       "392          0.105049         -0.094970                -0.094970  \n",
       "610          0.086390          0.048292                -0.048292  \n",
       "1316         0.430285         -0.213421                -0.213421  \n",
       "1269         0.319066         -0.166055                -0.166055  \n",
       "1265         0.173601          0.137140                -0.137140  \n",
       "276          0.166749          0.126942                -0.126942  \n",
       "1263         0.173601          0.122393                -0.122393  \n",
       "1293         0.178967         -0.105368                -0.105368  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df = dirty_df.merge(meandf, on = 'gbindex')\n",
    "dirty_df['error_divergence'] = dirty_df['dirty_error'] - dirty_df['clean_error']\n",
    "dirty_df['divergence_of_abs_error'] = dirty_df['dirty_abs_error'] - dirty_df['clean_abs_error']\n",
    "dirty_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "error0 = pd.read_csv('chunkmismatch/hathinocorrerrs0.tsv', sep = '\\t')\n",
    "error1 = pd.read_csv('chunkmismatch/hathinocorrerrs1.tsv', sep = '\\t')\n",
    "error2 = pd.read_csv('chunkmismatch/hathinocorrerrs2.tsv', sep = '\\t')\n",
    "error3 = pd.read_csv('chunkmismatch/hathinocorrerrs3.tsv', sep = '\\t')\n",
    "error4 = pd.read_csv('chunkmismatch/hathinocorrerrs4.tsv', sep = '\\t')\n",
    "#error5 = pd.read_csv('/Users/tunder/work/gh_align/hathichunkerrs5.tsv', sep = '\\t')\n",
    "chunkerrors = pd.concat([error0, error1, error2, error3, error4], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Word error (OCR) or passage fail (paratext)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chunkid', 'passagefails', 'worderrors'], dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkerrors.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkerrors = chunkerrors.merge(dirty_df, on = 'chunkid', how = 'left')\n",
    "chunkerrors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkerrors.dropna(inplace=True)\n",
    "chunkerrors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.042103836405116835, 0.11200328149064077)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['error_divergence'], chunkerrors['divergence_of_abs_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.06695231271526778, 0.011442003504967421)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['passagefails'], chunkerrors['error_divergence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.03868083038226551, 0.14430463388372888)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['passagefails'], chunkerrors['divergence_of_abs_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0904737345761333, 0.0006249980266686266)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['worderrors'], chunkerrors['error_divergence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07183888858130313, 0.006648860489540979)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['worderrors'], chunkerrors['divergence_of_abs_error']) #More OCR/word error than paratext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.062333850462691805, 0.018567515156947167)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['passagefails'], np.abs(chunkerrors['error_divergence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008311712922828434, 0.7538244584168414)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['worderrors'], np.abs(chunkerrors['error_divergence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Here, it looks like paratext is positively correlated with less accurate results (higher div of absolute error) -- so like we expected, paratext differences or \"passage fails\" are our primary suspects for error when dealing with fic v bios. \n",
    "\n",
    "In terms of direction, I think both more OCR error and more paratext/passage fail makes the model more likely to predict that the chunk comes from a biography. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06986153838338349, 0.008313827760232189)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(chunkerrors['passagefails'], chunkerrors['worderrors']) #Not a high correlation (less chance of collinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               OLS Regression Results                              \n",
      "===================================================================================\n",
      "Dep. Variable:     divergence_of_abs_error   R-squared:                       0.007\n",
      "Model:                                 OLS   Adj. R-squared:                  0.006\n",
      "Method:                      Least Squares   F-statistic:                     5.073\n",
      "Date:                     Thu, 01 Jul 2021   Prob (F-statistic):            0.00638\n",
      "Time:                             07:53:55   Log-Likelihood:                 708.89\n",
      "No. Observations:                     1426   AIC:                            -1412.\n",
      "Df Residuals:                         1423   BIC:                            -1396.\n",
      "Df Model:                                2                                         \n",
      "Covariance Type:                 nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.0533      0.005    -10.890      0.000      -0.063      -0.044\n",
      "passagefails    -0.0317      0.019     -1.658      0.097      -0.069       0.006\n",
      "worderrors       0.2747      0.097      2.829      0.005       0.084       0.465\n",
      "==============================================================================\n",
      "Omnibus:                      472.287   Durbin-Watson:                   1.734\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2169.415\n",
      "Skew:                           1.503   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.242   Cond. No.                         25.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y = chunkerrors['divergence_of_abs_error']\n",
    "X = sm.add_constant(chunkerrors.loc[ : , ['passagefails', 'worderrors']])\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       error_divergence   R-squared:                       0.014\n",
      "Model:                            OLS   Adj. R-squared:                  0.012\n",
      "Method:                 Least Squares   F-statistic:                     9.796\n",
      "Date:                Thu, 01 Jul 2021   Prob (F-statistic):           5.95e-05\n",
      "Time:                        07:53:55   Log-Likelihood:                 638.46\n",
      "No. Observations:                1426   AIC:                            -1271.\n",
      "Df Residuals:                    1423   BIC:                            -1255.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.0024      0.005     -0.469      0.639      -0.013       0.008\n",
      "passagefails    -0.0560      0.020     -2.790      0.005      -0.095      -0.017\n",
      "worderrors       0.3697      0.102      3.623      0.000       0.170       0.570\n",
      "==============================================================================\n",
      "Omnibus:                      110.874   Durbin-Watson:                   1.560\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              350.883\n",
      "Skew:                          -0.360   Prob(JB):                     6.41e-77\n",
      "Kurtosis:                       5.321   Cond. No.                         25.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y = chunkerrors['error_divergence']\n",
    "X = sm.add_constant(chunkerrors.loc[ : , ['passagefails', 'worderrors']])\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis -- What is it about these chunks that distorts the model?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkid</th>\n",
       "      <th>passagefails</th>\n",
       "      <th>worderrors</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>dirty_error</th>\n",
       "      <th>dirty_abs_error</th>\n",
       "      <th>clean_error</th>\n",
       "      <th>clean_abs_error</th>\n",
       "      <th>error_divergence</th>\n",
       "      <th>divergence_of_abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49154_0</td>\n",
       "      <td>0.25348</td>\n",
       "      <td>0.00373</td>\n",
       "      <td>49154</td>\n",
       "      <td>0.891056</td>\n",
       "      <td>0.891056</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.578716</td>\n",
       "      <td>0.578716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49154_1</td>\n",
       "      <td>0.04947</td>\n",
       "      <td>0.00665</td>\n",
       "      <td>49154</td>\n",
       "      <td>0.461531</td>\n",
       "      <td>0.461531</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.149191</td>\n",
       "      <td>0.149191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49154_2</td>\n",
       "      <td>0.06392</td>\n",
       "      <td>0.00883</td>\n",
       "      <td>49154</td>\n",
       "      <td>0.067340</td>\n",
       "      <td>0.067340</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>-0.245001</td>\n",
       "      <td>-0.245001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49154_3</td>\n",
       "      <td>0.04655</td>\n",
       "      <td>0.00691</td>\n",
       "      <td>49154</td>\n",
       "      <td>0.390289</td>\n",
       "      <td>0.390289</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.077949</td>\n",
       "      <td>0.077949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49154_4</td>\n",
       "      <td>0.04689</td>\n",
       "      <td>0.01022</td>\n",
       "      <td>49154</td>\n",
       "      <td>0.166384</td>\n",
       "      <td>0.166384</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>0.31234</td>\n",
       "      <td>-0.145957</td>\n",
       "      <td>-0.145957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunkid  passagefails  worderrors gbindex  dirty_error  dirty_abs_error  \\\n",
       "4  49154_0       0.25348     0.00373   49154     0.891056         0.891056   \n",
       "5  49154_1       0.04947     0.00665   49154     0.461531         0.461531   \n",
       "6  49154_2       0.06392     0.00883   49154     0.067340         0.067340   \n",
       "7  49154_3       0.04655     0.00691   49154     0.390289         0.390289   \n",
       "8  49154_4       0.04689     0.01022   49154     0.166384         0.166384   \n",
       "\n",
       "   clean_error  clean_abs_error  error_divergence  divergence_of_abs_error  \n",
       "4      0.31234          0.31234          0.578716                 0.578716  \n",
       "5      0.31234          0.31234          0.149191                 0.149191  \n",
       "6      0.31234          0.31234         -0.245001                -0.245001  \n",
       "7      0.31234          0.31234          0.077949                 0.077949  \n",
       "8      0.31234          0.31234         -0.145957                -0.145957  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkerrors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "topchunks = chunkerrors.sort_values('divergence_of_abs_error', ascending =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunks to inspect: 34240_9, 54218_1, 52603_8, 30236_4, PsalGMPbio_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunkid</th>\n",
       "      <th>passagefails</th>\n",
       "      <th>worderrors</th>\n",
       "      <th>gbindex</th>\n",
       "      <th>dirty_error</th>\n",
       "      <th>dirty_abs_error</th>\n",
       "      <th>clean_error</th>\n",
       "      <th>clean_abs_error</th>\n",
       "      <th>error_divergence</th>\n",
       "      <th>divergence_of_abs_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>34240_9</td>\n",
       "      <td>0.93627</td>\n",
       "      <td>0.00967</td>\n",
       "      <td>34240</td>\n",
       "      <td>-0.976945</td>\n",
       "      <td>0.976945</td>\n",
       "      <td>-0.207698</td>\n",
       "      <td>0.207698</td>\n",
       "      <td>-0.769246</td>\n",
       "      <td>0.769246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>54218_1</td>\n",
       "      <td>0.01243</td>\n",
       "      <td>0.00408</td>\n",
       "      <td>54218</td>\n",
       "      <td>0.954232</td>\n",
       "      <td>0.954232</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>0.762047</td>\n",
       "      <td>0.762047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>52603_8</td>\n",
       "      <td>0.01213</td>\n",
       "      <td>0.01518</td>\n",
       "      <td>52603</td>\n",
       "      <td>-0.954148</td>\n",
       "      <td>0.954148</td>\n",
       "      <td>-0.275409</td>\n",
       "      <td>0.275409</td>\n",
       "      <td>-0.678739</td>\n",
       "      <td>0.678739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>30236_4</td>\n",
       "      <td>0.44603</td>\n",
       "      <td>0.01463</td>\n",
       "      <td>30236</td>\n",
       "      <td>-0.928959</td>\n",
       "      <td>0.928959</td>\n",
       "      <td>-0.277265</td>\n",
       "      <td>0.277265</td>\n",
       "      <td>-0.651694</td>\n",
       "      <td>0.651694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>PsalGMPbio_1</td>\n",
       "      <td>0.00524</td>\n",
       "      <td>0.15943</td>\n",
       "      <td>PsalGMPbio</td>\n",
       "      <td>0.842436</td>\n",
       "      <td>0.842436</td>\n",
       "      <td>0.190883</td>\n",
       "      <td>0.190883</td>\n",
       "      <td>0.651553</td>\n",
       "      <td>0.651553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>40205_4</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.02673</td>\n",
       "      <td>40205</td>\n",
       "      <td>0.865329</td>\n",
       "      <td>0.865329</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.638373</td>\n",
       "      <td>0.638373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>30749_4</td>\n",
       "      <td>0.01141</td>\n",
       "      <td>0.01638</td>\n",
       "      <td>30749</td>\n",
       "      <td>-0.889256</td>\n",
       "      <td>0.889256</td>\n",
       "      <td>-0.285175</td>\n",
       "      <td>0.285175</td>\n",
       "      <td>-0.604081</td>\n",
       "      <td>0.604081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>30749_9</td>\n",
       "      <td>0.16558</td>\n",
       "      <td>0.01466</td>\n",
       "      <td>30749</td>\n",
       "      <td>-0.863997</td>\n",
       "      <td>0.863997</td>\n",
       "      <td>-0.285175</td>\n",
       "      <td>0.285175</td>\n",
       "      <td>-0.578822</td>\n",
       "      <td>0.578822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49154_0</td>\n",
       "      <td>0.25348</td>\n",
       "      <td>0.00373</td>\n",
       "      <td>49154</td>\n",
       "      <td>0.891056</td>\n",
       "      <td>0.891056</td>\n",
       "      <td>0.312340</td>\n",
       "      <td>0.312340</td>\n",
       "      <td>0.578716</td>\n",
       "      <td>0.578716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>57472_2</td>\n",
       "      <td>0.04499</td>\n",
       "      <td>0.01597</td>\n",
       "      <td>57472</td>\n",
       "      <td>0.904472</td>\n",
       "      <td>0.904472</td>\n",
       "      <td>0.338296</td>\n",
       "      <td>0.338296</td>\n",
       "      <td>0.566176</td>\n",
       "      <td>0.566176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           chunkid  passagefails  worderrors     gbindex  dirty_error  \\\n",
       "2125       34240_9       0.93627     0.00967       34240    -0.976945   \n",
       "2283       54218_1       0.01243     0.00408       54218     0.954232   \n",
       "126        52603_8       0.01213     0.01518       52603    -0.954148   \n",
       "2181       30236_4       0.44603     0.01463       30236    -0.928959   \n",
       "1401  PsalGMPbio_1       0.00524     0.15943  PsalGMPbio     0.842436   \n",
       "204        40205_4       0.05963     0.02673       40205     0.865329   \n",
       "2276       30749_4       0.01141     0.01638       30749    -0.889256   \n",
       "2281       30749_9       0.16558     0.01466       30749    -0.863997   \n",
       "4          49154_0       0.25348     0.00373       49154     0.891056   \n",
       "664        57472_2       0.04499     0.01597       57472     0.904472   \n",
       "\n",
       "      dirty_abs_error  clean_error  clean_abs_error  error_divergence  \\\n",
       "2125         0.976945    -0.207698         0.207698         -0.769246   \n",
       "2283         0.954232     0.192185         0.192185          0.762047   \n",
       "126          0.954148    -0.275409         0.275409         -0.678739   \n",
       "2181         0.928959    -0.277265         0.277265         -0.651694   \n",
       "1401         0.842436     0.190883         0.190883          0.651553   \n",
       "204          0.865329     0.226957         0.226957          0.638373   \n",
       "2276         0.889256    -0.285175         0.285175         -0.604081   \n",
       "2281         0.863997    -0.285175         0.285175         -0.578822   \n",
       "4            0.891056     0.312340         0.312340          0.578716   \n",
       "664          0.904472     0.338296         0.338296          0.566176   \n",
       "\n",
       "      divergence_of_abs_error  \n",
       "2125                 0.769246  \n",
       "2283                 0.762047  \n",
       "126                  0.678739  \n",
       "2181                 0.651694  \n",
       "1401                 0.651553  \n",
       "204                  0.638373  \n",
       "2276                 0.604081  \n",
       "2281                 0.578822  \n",
       "4                    0.578716  \n",
       "664                  0.566176  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topchunks[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
